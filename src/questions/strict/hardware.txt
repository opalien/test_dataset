### CONTEXT ###
"""
{article_text}
"""

### INSTRUCTION ###
You are an expert information extractor.
Your task is to identify the hardware used to train the model {model_name}. The wording in the article may differ slightly, but it must clearly refer to the same model.

Return exactly one Python list with two strings: ["value", "sentence"].
- "value": the hardware name(s) only (vendor + accelerator/class), with every quantity removed (e.g., "NVIDIA H100 GPUs", "Google TPU v5p pods").
- "sentence": the full sentence from the article that states which hardware trained {model_name}.

### RULES ###
1. Focus strictly on the training hardware for {model_name}. Ignore hardware for inference, evaluation, deployment, or other models.
2. Strip counts: if the sentence says "512 NVIDIA H100 GPUs", return "NVIDIA H100 GPUs". Do not include numbers, node counts, or rack sizes in the value.
3. If multiple hardware types are listed, select the one most directly tied to the primary training run of {model_name}.
4. If no training hardware is explicitly mentioned, return ["", ""].
5. Use the COMPLETE hardware identifier with format: {Brand} {Model} {Variant} (e.g., "NVIDIA GeForce GTX 1080 Ti GPU", "NVIDIA Tesla V100 SXM2 32GB GPU", "Google TPU v4s"). If training was not on GPU, specify the CPU or other hardware (e.g., "Intel Core i7-7700K CPU").

### EXAMPLES ###
Context: "We trained the 8B variant of {model_name} on 512 NVIDIA H100 GPUs across 64 nodes."
Output: ["NVIDIA H100 GPUs", "We trained the 8B variant of {model_name} on 512 NVIDIA H100 GPUs across 64 nodes."]

Context: "{model_name} pretraining ran on Google TPU v5p pods, while inference uses CPUs."
Output: ["Google TPU v5p pods", "{model_name} pretraining ran on Google TPU v5p pods, while inference uses CPUs."]

Context: "Inference uses Edge TPUs on-device."
Output: ["", ""]

Where "..." indicates the rest of the sentence; always return the entire sentence without modification.

